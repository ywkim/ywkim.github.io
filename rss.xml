<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Infinite Adventures Blog RSS Feed]]></title><description><![CDATA[Exploring the Boundless Horizons of Knowledge and Inspiration through Infinite Adventures.]]></description><link>https://ywkim.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Thu, 06 Jul 2023 07:41:57 GMT</lastBuildDate><item><title><![CDATA[Enhancing Iris: Unleashing Potential with LangChain Integration]]></title><description><![CDATA[Introduction In the world of open-source projects, it's always exciting to see different technologies come together to create something newâ€¦]]></description><link>https://ywkim.github.io/enhancing-iris-with-langchain-integration/</link><guid isPermaLink="false">https://ywkim.github.io/enhancing-iris-with-langchain-integration/</guid><pubDate>Wed, 05 Jul 2023 03:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/cc0239923626b726b05de1a458bf3405/3ceac/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVR42gGfAmD9ABUMBxgOCCATDCcXETIhGDIhGzIiHTIkITAlJjYvMDQvMzgxNSwvOTAyOS0sLzAoJT0pHTUeEwcEBQICBACTZkG4g1i7iF/DkGerfVq6iWa8jGmugmOieF5mST9iSD+SaFNmTkNnTkN2V0ZmRzlHMChFJRsrFREAAQcA05Zf/8aE/MmO/9eaz6h39MqR/9yh8cqU5LWAJxUMIxILpG9LUjEeUzMmfVtNXUZDRTM0LCEjQSEXBwQIAMaHVPy0c/i5f//Ij9OicvO/hf3Mku25gt6mcjAeGDYhGZdoTJNqVYlyapGCfoKBhUxecCIzRiogJB4NCACCUTK0c0i0dkvOjV+xelXOk2rapX7OmHO3iGg3LClOMiWDWT59dG5bgZhOhqKBwtV0mK8bQ2IjKTQfDAcAOx8PfE8rqXZHnmpDfVY8i2FKrnZaonZYhGpaOC0qVTYlZkIjYWNiW4ynW6TCa8rlhrTNMFp7JS89LRQNAB4OB3ZEI3pQL0AnGnxeRIxfSJtbQn1XR3RbUlQ2JVc4JXVMLW1RQGdmall6j014k193ik5NVB0bJCEPCwCmcT68jE48HhAOBgdsTTV2UztZQjdqTD57WkiLXkF9VDyMXEGra0VsSTdMOjdJOTgZEhQuISBAIhwYCwgA4plS97RifEMhFwkHFAYGEwYEOB0Qhk0ujlMzgEsvcUUubEUxiV1DkmFEd089Uzw3JyEmOB8cOBkQAwMGAOiXTOiUSYtAHCoRCREGBRoMCDokGFgzHl8zHFoxHEEmFzAfGScfISwuNz1FUTg4QSkjKyIbIioVExwNCgCCTiVtQR8jDgcYCwUNBgQLBAQhFA1FLR00IRUnGBAlFxAlGBIeGx4YIzIYLkIVIjATERUPDhMSCgsQCAanNc4U9EFslwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A modern living room with a smart home system integrated with Iris.&quot;
        title=&quot;&quot;
        src=&quot;/static/cc0239923626b726b05de1a458bf3405/f058b/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png&quot;
        srcset=&quot;/static/cc0239923626b726b05de1a458bf3405/c26ae/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 158w,
/static/cc0239923626b726b05de1a458bf3405/6bdcf/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 315w,
/static/cc0239923626b726b05de1a458bf3405/f058b/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 630w,
/static/cc0239923626b726b05de1a458bf3405/40601/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 945w,
/static/cc0239923626b726b05de1a458bf3405/78612/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 1260w,
/static/cc0239923626b726b05de1a458bf3405/3ceac/Envision_a_modern_living_room_with_a_smart_home_s_9436a86b-e8fd-4604-81b0-65d4c2c1e1ca.png 1456w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the world of open-source projects, it&apos;s always exciting to see different technologies come together to create something new and powerful. This is exactly what happened when I integrated LangChain, a Python library for building language model applications, into Iris, a multilingual voice assistant. The result is a more powerful and versatile voice assistant that can leverage the capabilities of LangChain&apos;s 17+ toolkits, including the ability to perform web searches, mathematical calculations, and more. This integration opens up a world of possibilities for developers and users alike, and I&apos;m excited to share it with you. If you&apos;re interested in contributing to this project, you can find Iris on &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Integration of Iris and LangChain&lt;/h2&gt;
&lt;p&gt;Iris, a multilingual voice assistant, has been a useful tool for many users, providing a unique blend of advanced AI capabilities and user-friendly interaction. However, we saw an opportunity to enhance Iris&apos;s capabilities even further by integrating it with LangChain.&lt;/p&gt;
&lt;p&gt;LangChain is a powerful tool that offers a wide range of features, including more than 17 different toolkits and the ability to use OpenAI&apos;s LLM and Chat models. By integrating LangChain into Iris, we can leverage these features to make Iris even more powerful and versatile.&lt;/p&gt;
&lt;p&gt;The integration process involves replacing the existing chat feature in Iris with LangChain&apos;s &lt;code class=&quot;language-text&quot;&gt;ChatOpenAI&lt;/code&gt; class, which uses OpenAI&apos;s Chat models. We also added a &lt;code class=&quot;language-text&quot;&gt;ConversationBufferMemory&lt;/code&gt; to Iris, which allows the assistant to remember past interactions and provide more contextually relevant responses. Additionally, we incorporated several of LangChain&apos;s &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/tools/&quot;&gt;toolkits&lt;/a&gt; into Iris, including the SerpAPI for answering questions about current events.&lt;/p&gt;
&lt;p&gt;The result of this integration is a more powerful and versatile Iris that can provide even more value to its users. In the following sections, we&apos;ll discuss the benefits of this integration and provide a detailed guide on how to integrate Iris and LangChain.&lt;/p&gt;
&lt;h2&gt;Benefits of Integration&lt;/h2&gt;
&lt;p&gt;The integration of Iris and LangChain brings several benefits that enhance the capabilities of Iris and provide a more enriching user experience.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enhanced Conversational Abilities&lt;/strong&gt;: With LangChain&apos;s &lt;code class=&quot;language-text&quot;&gt;ChatOpenAI&lt;/code&gt; class, Iris can now leverage the power of OpenAI&apos;s Chat models. This allows Iris to understand and respond to user commands in a more conversational manner, providing more meaningful and contextually relevant responses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Memory Feature&lt;/strong&gt;: The addition of &lt;code class=&quot;language-text&quot;&gt;ConversationBufferMemory&lt;/code&gt; allows Iris to remember past interactions. This feature enhances the conversational abilities of Iris by providing it with a context for its responses. It can remember past interactions and use this information to provide more relevant and personalized responses.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Access to Current Events&lt;/strong&gt;: The integration of the SerpAPI toolkit allows Iris to answer questions about current events. This feature is particularly useful for users who want to stay updated on the latest news and events.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Increased Versatility&lt;/strong&gt;: With access to LangChain&apos;s wide range of toolkits, Iris becomes a more versatile voice assistant. Users can customize Iris to suit their needs by adding or removing toolkits as required.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;: LangChain have active and growing communities. By integrating these two projects, we hope to foster collaboration and knowledge sharing between these communities.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the next section, we&apos;ll provide a detailed guide on how to integrate Iris and LangChain.&lt;/p&gt;
&lt;h3&gt;Expanding Iris&apos;s Capabilities with LangChain&lt;/h3&gt;
&lt;p&gt;By integrating LangChain into Iris, we&apos;ve unlocked a new level of functionality and versatility. Let&apos;s take a closer look at how this integration enhances Iris&apos;s capabilities.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; langchain &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; load_tools&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ChatOpenAI&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ConversationBufferMemory

&lt;span class=&quot;token comment&quot;&gt;# Initialize the chat model with OpenAI&lt;/span&gt;
chat &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ChatOpenAI&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
    model&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;settings&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;chat_model&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
    temperature&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;settings&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;temperature&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
    openai_api_key&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;api&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;openai_api_key&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Load the tools specified in the configuration&lt;/span&gt;
tools &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; load_tools&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;parse_list&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;settings&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;tools&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;# Initialize the memory buffer to remember the conversation context&lt;/span&gt;
memory &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ConversationBufferMemory&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;memory_key&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;memory&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; return_messages&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Utilizing a Variety of Tools&lt;/strong&gt;: With the &lt;code class=&quot;language-text&quot;&gt;load_tools&lt;/code&gt; function, we can now harness the power of LangChain&apos;s diverse toolkit to extend the functionality of Iris. This means Iris can do more than just respond to user commands - it can perform a variety of tasks, such as web searches, using the tools we&apos;ve loaded.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Context-Aware Conversations&lt;/strong&gt;: By using &lt;code class=&quot;language-text&quot;&gt;ChatOpenAI&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;ConversationBufferMemory&lt;/code&gt;, Iris can remember past conversations and respond to user queries in context. This makes interactions with Iris more natural and meaningful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Customization and Extensibility&lt;/strong&gt;: The changes we&apos;ve made to the code demonstrate how easily Iris can be customized and extended. This opens up a world of possibilities for you to explore, whether you&apos;re interested in building your own voice assistant or tailoring Iris to your specific needs.&lt;/p&gt;
&lt;p&gt;With these enhancements, we hope to inspire you to explore the potential of voice assistant technology and to consider the exciting possibilities that Iris and LangChain can offer.&lt;/p&gt;
&lt;h2&gt;The Future of Iris with LangChain&lt;/h2&gt;
&lt;p&gt;The integration of LangChain into Iris is just the beginning. With LangChain&apos;s extensive toolkit, Iris can now perform a wider range of tasks and provide more detailed and accurate responses. For example, Iris can now use the &quot;serpapi&quot; tool to answer questions about current events, or the &quot;math&quot; tool to perform complex calculations. This makes Iris not just a voice assistant, but a powerful tool for information retrieval and problem-solving.&lt;/p&gt;
&lt;p&gt;But the real power of this integration lies in its potential for future development. With LangChain&apos;s modular design, new tools can be easily added to Iris, allowing it to adapt and grow with the needs of its users. This could lead to innovative applications, such as integrating Iris with smart home systems, or using it as a tool for education and learning. The possibilities are endless, and I can&apos;t wait to see what the community will come up with. If you have any ideas or want to contribute, you can join us on &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The integration of LangChain into Iris represents a significant step forward in the development of open-source voice assistants. By combining the power of LangChain&apos;s language model applications with Iris&apos;s voice recognition and response capabilities, we&apos;ve created a voice assistant that is not only more capable, but also more adaptable and extensible. This integration opens up a world of possibilities for developers and users alike, and I&apos;m excited to see where it will lead us in the future.&lt;/p&gt;
&lt;p&gt;For more information about LangChain and its toolkits, you can visit the &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/tools/&quot;&gt;official documentation&lt;/a&gt;. If you&apos;re interested in contributing to Iris or have any ideas for new features or improvements, feel free to reach out or contribute on &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;GitHub&lt;/a&gt;. Together, we can make Iris even better.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Join the Journey of Iris: Building a Multilingual Voice Assistant with OpenAI and Picovoice]]></title><description><![CDATA[Introduction Welcome to the journey of creating your own voice-activated AI assistant. This blog post will guide you through the process ofâ€¦]]></description><link>https://ywkim.github.io/building-multilingual-voice-assistant-iris-openai-picovoice/</link><guid isPermaLink="false">https://ywkim.github.io/building-multilingual-voice-assistant-iris-openai-picovoice/</guid><pubDate>Mon, 03 Jul 2023 10:43:00 GMT</pubDate><content:encoded>&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Welcome to the journey of creating your own voice-activated AI assistant. This blog post will guide you through the process of setting up and customizing &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;Iris&lt;/a&gt;, a simple yet powerful voice assistant built using Python and a few powerful libraries and APIs.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/a3e3745126821296c5bcd5d153a39daf/3ceac/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
    &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAACnUlEQVR42gXB+0sTcQAA8Kum293Ozd1r39vd1m63zd3t4W3tvbmHt5fz2kO3qdNNyxemFkpOUAkMRAgiEiKkfg2iX4SMkPoxosgf/CmCfuw/6C+ozwdCNJRaTd5iaJeRtjMugRW8rCPEiRLNKkOuhuCacbvWg4Gqk1sUbV0P3xkyLzktQcboNhshBKHViClrt4adQj5SViLxdibfTJayvP0gnT3Nj5zVS1erK4fZ8GUj9H4y+a4Y+amEG04TR2MQRthhyhuc3crX5ttJuRXyrKSTK4mE4uRelmJvKomP3fKf+9kjWfy9N/HtXu7Lw8Lf18rGqK0s0hCJcdfN0eXt3p36xELE3UwF5krjuxXlrpz7tTl6sd3+evzgU6/eivgvn0x9Ppj8cVD4972zOxvM2RlIqzUhFp/fL1RjjnIqWJyeaS3s76/1jvcOzw+3zk6Ort4+f7G9VskpH056r04enz59dr4zV42GR4acEK5jtHqrgeGj8ogyvdRY3JEKy77SajDVLBbb8/nqxqgccSdjqcmLg9nNsWS+3IyHx6biyW7CB6nUrAp1mm0xR6Fj9SkCn07Hq8vre51xpShKLtya4cVyLN0qVhoBL2eyMUAMDMvtbDnr4CAdzJp0NjfwFqcfAWnmGpHQ35QZYUxyhAAh6kEUWFPVSKYkegkDS2GMHqWAHnAYTaI4JOho/yAtUbyU6YbCdb8lEONjGXnBA9wJeyov3Y4LBd5ZkiyibgCgWiOKUFoNYdDiGIpDJoRiUGDRm0UDkzRQeYIaN4IySSmArjFsjTHXGIuHsBM664CWQjQkrCZgNQ5r8AG1AYL7CRQGgwiNaSiDhsJgkoQJgOAcig9jZAKAHGuSCGO/iuxT4X0q7IYK06kNpBYzwoP/AQ9/lluOgV8qAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A man is relaxing on a couch, speaking to an AI voice assistant integrated into his smart home system.&quot;
        title=&quot;&quot;
        src=&quot;/static/a3e3745126821296c5bcd5d153a39daf/f058b/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png&quot;
        srcset=&quot;/static/a3e3745126821296c5bcd5d153a39daf/c26ae/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 158w,
/static/a3e3745126821296c5bcd5d153a39daf/6bdcf/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 315w,
/static/a3e3745126821296c5bcd5d153a39daf/f058b/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 630w,
/static/a3e3745126821296c5bcd5d153a39daf/40601/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 945w,
/static/a3e3745126821296c5bcd5d153a39daf/78612/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 1260w,
/static/a3e3745126821296c5bcd5d153a39daf/3ceac/Picture_a_cozy_home_environment_in_the_evening._A_bcdb51fd-cf55-4007-a2b6-46b350eb8e4f.png 1456w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
        decoding=&quot;async&quot;
      /&gt;
  &lt;/a&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Iris is named after the Greek goddess of the rainbow and messenger of the gods. Just like Iris from the mythology, our Iris is also a messenger. It listens to your voice commands, processes them, and delivers the appropriate response. The name &quot;Iris&quot; is pronounced in Spanish, and you can listen to the correct pronunciation &lt;a href=&quot;https://github.com/ywkim/iris/blob/main/iris.mp3&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What sets Iris apart from other voice assistants is its ability to understand and respond in multiple languages, its use of the latest AI models for understanding and generating human-like responses, and its open-source nature that invites contributions from developers around the world.&lt;/p&gt;
&lt;p&gt;The beauty of Iris lies in its simplicity and customizability. It uses &lt;a href=&quot;https://picovoice.ai/products/porcupine/&quot;&gt;Picovoice&apos;s Porcupine&lt;/a&gt; for wake word detection, &lt;a href=&quot;https://openai.com/research/&quot;&gt;OpenAI&apos;s GPT&lt;/a&gt; models for generating responses, and &lt;a href=&quot;https://github.com/Jiangshan00001/pyttsx4&quot;&gt;pyttsx4&lt;/a&gt; for text-to-speech conversion. Each of these components can be customized to suit your needs, making Iris a great starting point for anyone interested in building their own voice assistant.&lt;/p&gt;
&lt;p&gt;In this blog post, we will delve into the details of the Iris project, explore the technologies it uses, and provide a practical guide on how to use and contribute to Iris. Whether you&apos;re a developer looking to build your own voice assistant, a tech enthusiast curious about the latest in voice assistant technology, or someone interested in contributing to an open-source project, this blog post has something for you.&lt;/p&gt;
&lt;p&gt;We hope that this blog post will not only provide you with valuable insights into the Iris project but also inspire you to explore the fascinating world of voice assistant technology and AI. Let&apos;s get started!&lt;/p&gt;
&lt;h1&gt;Getting Started with Iris&lt;/h1&gt;
&lt;h2&gt;Understanding Iris&lt;/h2&gt;
&lt;p&gt;Iris is a voice-activated AI assistant that listens for a wake word, transcribes subsequent speech into text, generates a response using OpenAI&apos;s GPT model, and speaks the response back to the user. It&apos;s a fully voice-operated system, meaning you don&apos;t need to type anything to interact with Iris. It&apos;s designed to be simple, efficient, and customizable, making it a great starting point for anyone interested in building their own voice assistant.&lt;/p&gt;
&lt;h2&gt;Setting Up Iris&lt;/h2&gt;
&lt;p&gt;Setting up Iris is straightforward. You&apos;ll need &lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;Python 3.8&lt;/a&gt; or higher and the &lt;a href=&quot;https://python-poetry.org/docs/#installation&quot;&gt;Poetry package manager&lt;/a&gt;. Once you have these prerequisites, you can clone the &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;Iris repository&lt;/a&gt; from GitHub and install the necessary dependencies with Poetry.&lt;/p&gt;
&lt;p&gt;After that, you&apos;ll need to obtain an &lt;a href=&quot;https://beta.openai.com/signup/&quot;&gt;OpenAI API key&lt;/a&gt; for the GPT model and a &lt;a href=&quot;https://picovoice.ai/console/&quot;&gt;Picovoice AccessKey&lt;/a&gt; for the wake word detection. These keys should be placed in a &lt;code class=&quot;language-text&quot;&gt;config.ini&lt;/code&gt; file in the root directory of the project.&lt;/p&gt;
&lt;p&gt;Finally, you can run Iris using the command &lt;code class=&quot;language-text&quot;&gt;poetry run python main.py&lt;/code&gt;. Iris will start listening for the wake word and respond to your commands.&lt;/p&gt;
&lt;h2&gt;Customizing Iris&lt;/h2&gt;
&lt;p&gt;One of the great features of Iris is its customizability. You can change the wake word from the default &quot;jarvis&quot; to anything you want by using a &lt;a href=&quot;https://picovoice.ai/console/&quot;&gt;custom wake word model&lt;/a&gt; from Picovoice. You can also change the voice of Iris&apos;s responses by modifying the &lt;code class=&quot;language-text&quot;&gt;voice&lt;/code&gt; setting in the &lt;code class=&quot;language-text&quot;&gt;config.ini&lt;/code&gt; file.&lt;/p&gt;
&lt;h2&gt;Expanding Iris&lt;/h2&gt;
&lt;p&gt;While Iris is a fully functional voice assistant as it is, there&apos;s always room for improvement and expansion. You could add more features, like the ability to control smart home devices, set reminders, or even tell jokes. The possibilities are only limited by your imagination and coding skills. If you come up with a great idea or improvement, don&apos;t hesitate to &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;contribute to the project&lt;/a&gt; on GitHub.&lt;/p&gt;
&lt;p&gt;Remember, Iris is just the beginning. It&apos;s a foundation upon which you can build your own unique voice assistant. So get started, experiment, and most importantly, have fun!&lt;/p&gt;
&lt;h1&gt;Deep Dive into Iris&apos;s Technology Stack&lt;/h1&gt;
&lt;p&gt;In this section, we&apos;ll take a closer look at the technologies that power Iris. We&apos;ll start with how Iris listens for its wake word to start processing commands, then we&apos;ll move on to how it detects when you&apos;re speaking and transcribes your speech into text. Let&apos;s dive in!&lt;/p&gt;
&lt;h2&gt;Wake Word Detection with Porcupine&lt;/h2&gt;
&lt;p&gt;The first step in interacting with Iris is to get its attention, and we do this with a &quot;wake word&quot;. A wake word is a special phrase that the system is always listening for, which tells it to wake up and start processing further speech as commands or queries. In our case, we&apos;re using a default wake word of &quot;Jarvis&quot;.&lt;/p&gt;
&lt;p&gt;To implement wake word detection, we&apos;re using the &lt;a href=&quot;https://picovoice.ai/products/porcupine/&quot;&gt;Porcupine&lt;/a&gt; library. Porcupine is a highly-accurate and lightweight wake word detection library that works on-device, meaning it doesn&apos;t need to send any data to the cloud. This is great for privacy and efficiency.&lt;/p&gt;
&lt;p&gt;Here&apos;s a snippet of the code that sets up the wake word listener in Iris:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;PorcupineWakeWordListener&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; access_key&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; keyword_paths&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model_path&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;porcupine &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pvporcupine&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;create&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
            access_key&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;access_key&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; keyword_paths&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;keyword_paths&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; model_path&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;model_path
        &lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        audio_device_index &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;
        self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;recorder &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; PvRecorder&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
            device_index&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;audio_device_index&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; frame_length&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;porcupine&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;frame_length
        &lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One of the cool features of Porcupine is that it allows you to define your own custom wake words. This means you can personalize Iris to respond to a different name if you want! To do this, you&apos;ll need to use the &lt;a href=&quot;https://console.picovoice.ai/&quot;&gt;Picovoice Console&lt;/a&gt; to create and train a model for your custom wake word, and then replace the default model file in the Iris configuration with your new one. This is a powerful feature that allows you to customize Iris without having to modify the code.&lt;/p&gt;
&lt;h2&gt;Voice Activity Detection and Transcription&lt;/h2&gt;
&lt;p&gt;Once Iris has been activated with the wake word, it needs to listen to what you say and convert that speech into text that it can process. This involves two steps: Voice Activity Detection (VAD) and transcription.&lt;/p&gt;
&lt;p&gt;VAD is the process of identifying when speech is happening. It&apos;s used to make sure Iris doesn&apos;t waste time and resources processing silence or background noise. For VAD, we&apos;re using the &lt;a href=&quot;https://pypi.org/project/SpeechRecognition/&quot;&gt;SpeechRecognition&lt;/a&gt; library&apos;s built-in functionality.&lt;/p&gt;
&lt;p&gt;After VAD, the next step is transcription, which is converting the detected speech into written text. For this, we&apos;re using OpenAI&apos;s Whisper ASR API. Whisper is an Automatic Speech Recognition (ASR) system that has been trained on a large amount of multilingual and multitask supervised data collected from the web. It&apos;s designed to convert spoken language into written text and works great for our purposes. You can learn more about it &lt;a href=&quot;https://openai.com/research/whisper/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Conversational AI with GPT&lt;/h2&gt;
&lt;p&gt;Once Iris has transcribed your speech into text, it needs to understand what you&apos;re asking and generate a meaningful response. For this, we&apos;re using OpenAI&apos;s GPT model.&lt;/p&gt;
&lt;p&gt;GPT, or Generative Pretrained Transformer, is a type of language processing AI model that&apos;s great at understanding and generating human-like text. It&apos;s been trained on a diverse range of internet text and can generate creative, coherent, and contextually relevant sentences. You can learn more about GPT &lt;a href=&quot;https://openai.com/research/gpt/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In our case, we&apos;re using the GPT model to power Iris&apos;s conversational abilities. When you ask Iris a question or give it a command, the text of your request is sent to the GPT model, which generates a response. This response is then spoken out loud by Iris, giving you the information or confirmation you asked for.&lt;/p&gt;
&lt;h2&gt;Text-to-Speech with pyttsx4&lt;/h2&gt;
&lt;p&gt;The final step in the Iris interaction process is speaking the generated response back to you. For this, we&apos;re using a text-to-speech (TTS) library called &lt;a href=&quot;https://github.com/Jiangshan00001/pyttsx4&quot;&gt;pyttsx4&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;pyttsx4 is a TTS library for Python that works offline and is compatible with both Python 2 and 3. It supports multiple TTS engines, including native ones on Windows, Mac, and Linux, and it can use any TTS voice installed on your system.&lt;/p&gt;
&lt;p&gt;In our Iris configuration, we&apos;ve set up pyttsx4 to use a specific voice, but you can change this to any voice you like. You can even install additional voices and use them with pyttsx4, allowing you to further customize how Iris sounds.&lt;/p&gt;
&lt;p&gt;And that&apos;s it! That&apos;s the technology stack that powers Iris.&lt;/p&gt;
&lt;h2&gt;Bringing It All Together&lt;/h2&gt;
&lt;p&gt;Now that we&apos;ve gone through each component of Iris&apos;s technology stack, let&apos;s take a step back and look at how it all fits together.&lt;/p&gt;
&lt;p&gt;When you say the wake word, Iris starts recording your voice. This recording is then transcribed into text using Whisper ASR. The transcribed text is sent to the GPT model, which generates a response. This response is then converted into speech using pyttsx4 and spoken out loud by Iris.&lt;/p&gt;
&lt;p&gt;This entire process happens in real-time and is completely hands-free, making Iris a truly voice-activated AI assistant. And the best part? All of this is customizable. You can change the wake word, the language, the voice of Iris, and even the AI model used for conversation.&lt;/p&gt;
&lt;p&gt;This level of customization makes Iris a versatile tool that can be adapted to a wide range of use cases. Whether you want a personal assistant to help you manage your schedule, a voice-activated controller for your smart home devices, or a conversational AI for your business, Iris can be tailored to meet your needs.&lt;/p&gt;
&lt;p&gt;And because Iris is open-source, you can dive into the code, understand how it works, and even contribute to its development. We believe in the power of community and collaboration, and we&apos;re excited to see what you can do with Iris.&lt;/p&gt;
&lt;h2&gt;Building Your Own Voice Assistant with Iris&lt;/h2&gt;
&lt;p&gt;Building your own voice assistant with Iris is as simple as cloning the &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;repository&lt;/a&gt; and setting up your configuration file. But the real power of Iris comes from its customizability. You can change the wake word, the language, the voice of Iris, and even the AI model used for conversation. This means you can tailor Iris to suit your specific needs and preferences.&lt;/p&gt;
&lt;p&gt;For example, if you&apos;re a business owner, you might want to use Iris as a voice-activated customer service assistant. You can customize the wake word to be your business name, and set up the AI model to respond to customer inquiries. Or if you&apos;re a developer, you can use Iris as a hands-free coding assistant, setting up the AI model to understand and respond to coding-related commands.&lt;/p&gt;
&lt;p&gt;The possibilities are endless, and we&apos;re excited to see what you can create with Iris.&lt;/p&gt;
&lt;h2&gt;Contributing to Iris&lt;/h2&gt;
&lt;p&gt;We believe in the power of community and collaboration, and we&apos;re excited to welcome contributors to Iris. Whether you&apos;re a developer looking to add new features, a designer wanting to improve the user interface, or a user who&apos;s found a bug, your contributions are valuable and appreciated.&lt;/p&gt;
&lt;p&gt;To contribute to Iris, you can start by exploring the &lt;a href=&quot;https://github.com/ywkim/iris&quot;&gt;code&lt;/a&gt; and understanding how it works. If you have an idea for a new feature or improvement, feel free to open an issue on the GitHub repository to discuss it. We&apos;re always open to new ideas and feedback.&lt;/p&gt;
&lt;p&gt;We also encourage you to join our &lt;a href=&quot;https://discord.gg/3cWK9Qmv&quot;&gt;Discord community&lt;/a&gt;, where you can connect with other Iris users and contributors, share your ideas, and get help with any issues you might encounter.&lt;/p&gt;
&lt;p&gt;By contributing to Iris, you&apos;re not only helping to improve the project, but also becoming part of a community of people passionate about voice technology and AI. We can&apos;t wait to see what you&apos;ll bring to Iris.&lt;/p&gt;
&lt;h2&gt;Real-world Applications of Voice Assistants&lt;/h2&gt;
&lt;p&gt;Voice assistants are becoming increasingly prevalent in our daily lives. From smart home devices to in-car systems, they provide a hands-free and intuitive way to interact with technology. Here are a few examples of how voice assistants like Iris are being used in the real world:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Smart Home Automation:&lt;/strong&gt; Voice assistants can control smart home devices, such as lights, thermostats, and security systems. For example, you can ask Iris to turn off the lights in your living room or adjust the temperature in your home.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Personal Assistance:&lt;/strong&gt; Voice assistants can help with tasks like setting reminders, making appointments, sending messages, and more. You can ask Iris to remind you of an upcoming meeting or send a message to a colleague.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accessibility:&lt;/strong&gt; For individuals with physical disabilities or mobility issues, voice assistants can provide a valuable tool for accessing technology and information.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Education:&lt;/strong&gt; In educational settings, voice assistants can be used to answer questions, provide explanations, and assist with learning. Iris, with its ability to use OpenAI&apos;s powerful GPT models, can be a helpful study companion.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Building a voice assistant like Iris is a fascinating journey into the world of voice technology and AI. It&apos;s a project that combines several different technologies to create a system that can understand and respond to voice commands. While Iris is a simple voice assistant, it demonstrates the potential of voice technology and how it can be customized and extended.&lt;/p&gt;
&lt;p&gt;Whether you&apos;re a developer looking to explore voice technology, a business owner considering a voice assistant for customer service, or a tech enthusiast curious about AI, we hope this blog post has provided you with valuable insights and inspired you to start your own journey with voice assistants.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://picovoice.ai/&quot;&gt;Picovoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Jiangshan00001/pyttsx4&quot;&gt;pyttsx4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pypi.org/project/SpeechRecognition/&quot;&gt;SpeechRecognition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item></channel></rss>